{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53937d5e-c780-400c-b35d-0f0ea8bdfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b751e806-9d28-4627-bdef-c419219692ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train'\n",
    "TEST_DIR = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9553e8c2-0e02-42fa-b364-0987f8f18ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490ce56-ebb8-4321-a524-cb89e4d3f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ef42c-f87d-4d48-b0b5-b0a99f221385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2b8ea-8466-4793-8e7d-1af8c6514075",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861fee9-6656-4196-82a1-135252f3f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "641c0b48-5273-4ca9-80f2-bcbf47cb9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba99bc25-f42c-4105-be24-ff90097a6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode=\"grayscale\")\n",
    "\n",
    "       # img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f886c-daaa-4b53-b021-b52fa500f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da606fa1-de48-4e0c-9438-0bd61a9af9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c4348c0-a77b-4560-961a-c6ad2b944be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ee6423-1eaf-4157-a638-a57b01b78640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98f53d-cb1b-46cd-ab17-18fe8cff0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d574fb-aa28-4da0-8f6b-3a22676b7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcb08714-25e0-46d1-92ba-907ff65fb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723cda64-e53c-425a-9bf9-d989efde02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df34710-0e44-4ca3-ba75-9cd2f9098761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6342d-5103-4a1a-a80e-032164462b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 0, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e3515-9961-4a86-80fd-bd0c831c3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b8566a3-5680-466a-b5f6-cb6d3cf3d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48b89858-4418-454a-8449-e3819b0b18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "#model = model_from_json(model_json)\n",
    "model = model_from_json(model_json, custom_objects={\"Sequential\": Sequential})\n",
    "model.load_weights(\"C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/facialemotionmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d68236e6-97b6-42f9-8819-103aeeedc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9725ca2-07da-45e8-b7ce-3108890621be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ef(image):\n",
    "    # Load image in grayscale\n",
    "    img = load_img(image, color_mode='grayscale', target_size=(48, 48))  # target_size ensures proper image size\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)  # Reshape to add the batch dimension\n",
    "    return feature / 255.0  # Normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d41a4b-f50a-4e63-8c2c-9f8567ec05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/sad/3.jpg'\n",
    "print(\"Original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is:\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd8093-36a7-4e5b-9440-10d7e74456c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/sad/3.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9e28e-f7ce-4a54-b306-3283756d2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/angry/0.jpg'\n",
    "print(\"Original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is:\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41583d42-4065-49e0-8a2d-77d815349263",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/happy/7.jpg'\n",
    "print(\"Original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is:\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92017c20-6e4c-448f-bf64-14efd258a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de664f5e-ee2f-4e58-a633-37976595695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/happy/7.jpg'\n",
    "print(\"original image is of happy\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738f3f7-fc6c-4a6d-b714-6c95f41f5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/angry/0.jpg'\n",
    "print(\"original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779b023-a2c5-4926-b925-9b1774eb407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=\"C:/Users/likes/OneDrive/portfolio/Desktop/Face Emotion Detection/images/train/sad/3.jpg\"\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881c94b-bd3d-4321-b272-9cfbe4c0a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
